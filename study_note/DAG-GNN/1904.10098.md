# DAG-GNN: DAG Structure Learning with Graph Neural Networks

Author: Yue Yu, Jie Chen, Tian Gao, Mo Yu  
Submitted on 22 Apr 2019  
Cite : [arXiv:1904.10098](https://arxiv.org/pdf/1904.10098.pdf),
Code : [GitHub](https://github.com/fishmoon1234/DAG-GNN)
***

![category](https://img.shields.io/badge/category-paper-00a0a0.svg?longCache=true)
![topic](https://img.shields.io/badge/topic-causal_analysis-a000a0.svg?longCache=true)
![progress](https://progress-bar.dev/10/?title=progress)

## 要約



## 逐語訳

### 概要

- 信頼性の高いDAGの学習はチャレンジングな課題である(ノード増加に伴って探索空間が爆発的に増えるため)
- 最近は非循環の条件を微分可能な最小化問題に落とし込むというブレイクスルーがあった
- ただ、彼らは線形の構造方程式(SEM)を仮定して、最小二乗法での損失関数を使っており、よく理解されている反面、制限の多い手法を使っていた。
- DLが複雑な非線形マッピングに対して幅広く応用されてきていることを受けて、DLを利用した構造的な制約を加えたDAGの学習方法を提案する。
- これはGNNを利用したVariational AutoEncoder(VAE)を使った手法になっており、DAG-GNNと名付けている。
- さらにより用途を拡張するために、ベクトル値と同様に、離散値を自然に扱えるようにした。
- 合成データを使ったデモでは、非線形を仮定して作られたサンプルに対しては、より正確な構造学習ができることを示した。
- 離散値を用いたデータでは、大域的最適化と遜色のない結果を示すことを確認した。

## 導入

ベイジアンネットワーク(BN)は機械学習分野で広く利用されてきた。
BNは有向非循環グラフ(DAG)の形式をとり、因果効果の中心的な役割を果たしている。
構造学習の課題はNP困難であり、組み合わせの爆発的増加が挙げられる。

スコアベースの手法は、不明な係数行列(A)に対するスコア関数を最適化するもので、グラフが非循環になるという制約が課されるものになる。
最適化の実質的な課題は、複雑な探索領域である。
そのため、実質的には、さらに構造上の仮定が必要になる。

近年、非循環の制約と等価な連続的な関数が導入された。
これにより、組み合わせ問題が連続値の最適化に劇的に変化し、しっかりしたブラックボックスな処理によって効率的に処理できる解決できる可能性が出てきた。
この最適化問題は、非線形なこともあるが、一般にグローバルな最適化というよりはある終端点に落ち着くようなものになっている。
とはいえ、そのようなローカルの解法が組み合わせ問題を時に行くようなグローバルな解法と同等な精度を発揮することも示している。

制限の再定式化にインスパイアされて、目的関数を再考した。
スコアベースの目的関数は、一般的に変数とモデルクラスの仮定を作ってしまう。
例えば、Zhengの論文では、線形のSEMを最小二乗法で最適化する方法をとっていた。
これは簡便であるが、厳しすぎるものになっていたり、実際のデータにマッチしていなかったりする。

そのため、深層学習に動機づけて、グラフベースの深層学習モデルを導入することによる、信頼性の高いDAGの学習手法を開発した。
最終的に、変分推論の仕組みを利用して、GNNを用いたエンコーダ/デコーダのペアをパラメタ化している。
この場合、目的関数(スコア)は、変分下限(ELBO)になる。
現在の一般的なGNNのデザインとは異なり、線形のSEMを元に組まれており、データが線形で説明でできるなら、線形SEMと同様の性能を示すようなものになっている。

この手法は以下の特徴や利点を持っている。
1. VAEの仕組みを使ったデータ分布のキャプチャとサンプリング。
    グラフの設定としては、係数行列は潜在的な構造ではなく、明示的なパラメータになっており、ネットワークの学習と一緒に学習できる。
    こうしたネットワークの仕組みはこれまで使われていなかった。
2. VAEはさまざまなデータタイプに対応でき、連続値だけでなく離散的なものにも対応できる。
    必要なことは、変数の性質と一致する尤度分布（デコーダー出力）をモデル化することだけになっている。
3. パラメタ化にGNNを用いるため、各変数(ノード)はスカラー値だけでなくベクトル値を扱うこともできる。
    これらの変数はGNNに対する入力/出力の特徴量になる。
4. この手法は、非循環の要求をより現在の深層学習の仕組みに実装しやすいものにしている。
    NO TEARSでは、行列の指数関数の形式を用いていており、これは数学的にはとても美しいが、実装が難しかったり、自動微分ができなかったりする。
    そのため、これを多項式の形で近似した、より実用的に扱いやすく、指数関数と数式的に相当に扱える形にした。

デモンストレーションとして、線形/非線形のSEMに基づいた合成データを用いた試験、離散値のベンチマークデータを用いた試験、そしてアプリケーションからのテストデータセットを用いたものを行った。
合成データに対しては、DAG-NOTEARSよりもDAG-GNNが優れた性能を示している。
ベンチマークデータに対する結果としては、組み合わせ探索によるベイズを利用した探索手法と同等の結果を示した。


### 背景と関連研究
### ニューラルネットでのDAG学習

### 実験

### 結論
